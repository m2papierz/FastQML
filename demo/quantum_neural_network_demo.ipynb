{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Multiclass Classification Using QNNClassifier with JAX Backend in FastQML\n",
    "\n",
    "This demonstration showcases the use of a Quantum Neural Network (QNN) Classifier within the FastQML framework. The QNNClassifier, leveraging the power of quantum computing, will be used for multiclass classification task. This demo employs the JAX backend to enhance computational efficiency, taking advantage of JAX's auto-differentiation and hardware acceleration features. The focus is on illustrating the setup, training, and evaluation of a quantum neural network for a practical classification problem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "522c79c6baa18213"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from fast_qml import device_manager\n",
    "from fast_qml.quantum_circuits.feature_maps import AngleEmbedding\n",
    "from fast_qml.quantum_circuits.variational_forms import EfficientSU2, TwoLocal\n",
    "from fast_qml.machine_learning.estimators.qnn import QNNClassifier\n",
    "from fast_qml.machine_learning.callbacks import EarlyStopping"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:14:58.613219800Z",
     "start_time": "2024-02-01T12:14:57.288790Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset used in this demonstration is the Iris dataset, a classic dataset in machine learning and statistics. It consists of 150 samples of iris flowers from three different species. Each sample has four features: the length and the width of the sepals and petals.\n",
    "\n",
    "The preprocessing steps include:\n",
    "- Normalizing the feature data to ensure effective training of the neural network.\n",
    "- Splitting the dataset into training, validation, and testing sets for a comprehensive evaluation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48a4b20a1b7308a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (23, 4) (22, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.3, shuffle=True, random_state=32)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, shuffle=True, random_state=32)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:02.336775Z",
     "start_time": "2024-02-01T12:15:02.328913700Z"
    }
   },
   "id": "ace702ff978e4e3f",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "The setup for the Quantum Neural Network includes:\n",
    "- Defining the number of qubits, which corresponds to the number of features in the dataset.\n",
    "- Choosing a feature map to encode classical data into quantum states.\n",
    "- Selecting an ansatz (variational form) which defines the structure of the quantum circuit used in the neural network.\n",
    "\n",
    "For the purpose of the demonstration AngleEmbedding feature map will be used with EfficientSU2 variational form."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb833204b2468738"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Number of qubits corresponding to the number of features in the dataset\n",
    "n_qubits = 4\n",
    "\n",
    "# AngleEmbedding encodes the number of features equal to number of qubits\n",
    "feature_map = AngleEmbedding(\n",
    "    n_qubits=n_qubits\n",
    ")\n",
    "\n",
    "# EfficientSU2 ansatz\n",
    "ansatz = EfficientSU2(\n",
    "    n_qubits=n_qubits,\n",
    "    entanglement='full',\n",
    "    skip_last_rotations=False,\n",
    "    reps=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:04.857061700Z",
     "start_time": "2024-02-01T12:15:04.853553700Z"
    }
   },
   "id": "e0d33e9ce75b0ba7",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having all components let's create a QNNClassifier and draw it's circuit."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991c9a3659f0b6c5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)──RY(0.07)──RX(0.10)─╭●─╭●─╭●───────────||──RY(0.09)──RX(0.03)──RY(0.08)\n",
      "1: ─├AngleEmbedding(M0)──RY(0.02)──RX(0.06)─╰X─│──│──╭●─╭●─────||──RY(0.02)──RX(0.03)──RY(0.06)\n",
      "2: ─├AngleEmbedding(M0)──RY(0.09)──RX(0.03)────╰X─│──╰X─│──╭●──||──RY(0.04)──RX(0.01)──RY(0.10)\n",
      "3: ─╰AngleEmbedding(M0)──RY(0.03)──RX(0.01)───────╰X────╰X─╰X──||──RY(0.09)──RX(0.01)──RY(0.08)\n",
      "\n",
      "───RX(0.04)─╭●─╭●─╭●───────────||──RY(0.08)──RX(0.08)─┤  \n",
      "───RX(0.09)─╰X─│──│──╭●─╭●─────||──RY(0.06)──RX(0.00)─┤  \n",
      "───RX(0.07)────╰X─│──╰X─│──╭●──||──RY(0.03)──RX(0.00)─┤  \n",
      "───RX(0.05)───────╰X────╰X─╰X──||──RY(0.03)──RX(0.07)─┤  \n",
      "M0 = \n",
      "[[ 0.56607921 -1.19795096 -0.13340007  0.01424333]]\n"
     ]
    }
   ],
   "source": [
    "# Create QNNClassifier model with defined ansatz and feature map\n",
    "model = QNNClassifier(\n",
    "    n_qubits=n_qubits,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    data_reuploading=False,\n",
    "    layers_num=2,\n",
    "    classes_num=3\n",
    ")\n",
    "\n",
    "model.draw_circuit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:07.356497900Z",
     "start_time": "2024-02-01T12:15:07.350883500Z"
    }
   },
   "id": "1afdb9dfdce3d257",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can fit the model, with validation and early stopping mechanism."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe3d7a550414f988"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - train_loss: 0.25145, val_loss: 0.26767\n",
      "Epoch 2/500 - train_loss: 0.21085, val_loss: 0.22471\n",
      "Epoch 3/500 - train_loss: 0.17795, val_loss: 0.18994\n",
      "Epoch 4/500 - train_loss: 0.15004, val_loss: 0.16075\n",
      "Epoch 5/500 - train_loss: 0.12591, val_loss: 0.13552\n",
      "Epoch 6/500 - train_loss: 0.10466, val_loss: 0.11320\n",
      "Epoch 7/500 - train_loss: 0.08614, val_loss: 0.09364\n",
      "Epoch 8/500 - train_loss: 0.07032, val_loss: 0.07691\n",
      "Epoch 9/500 - train_loss: 0.05738, val_loss: 0.06328\n",
      "Epoch 10/500 - train_loss: 0.04770, val_loss: 0.05310\n",
      "Epoch 11/500 - train_loss: 0.04130, val_loss: 0.04636\n",
      "Epoch 12/500 - train_loss: 0.03757, val_loss: 0.04247\n",
      "Epoch 13/500 - train_loss: 0.03558, val_loss: 0.04045\n",
      "Epoch 14/500 - train_loss: 0.03451, val_loss: 0.03948\n",
      "Epoch 15/500 - train_loss: 0.03398, val_loss: 0.03913\n",
      "Epoch 16/500 - train_loss: 0.03386, val_loss: 0.03920\n",
      "Epoch 17/500 - train_loss: 0.03402, val_loss: 0.03954\n",
      "Epoch 18/500 - train_loss: 0.03427, val_loss: 0.03998\n",
      "Epoch 19/500 - train_loss: 0.03451, val_loss: 0.04046\n",
      "Epoch 20/500 - train_loss: 0.03477, val_loss: 0.04102\n",
      "Epoch 21/500 - train_loss: 0.03508, val_loss: 0.04167\n",
      "Epoch 22/500 - train_loss: 0.03529, val_loss: 0.04223\n",
      "Epoch 23/500 - train_loss: 0.03513, val_loss: 0.04243\n",
      "Epoch 24/500 - train_loss: 0.03448, val_loss: 0.04213\n",
      "Epoch 25/500 - train_loss: 0.03341, val_loss: 0.04139\n",
      "Epoch 26/500 - train_loss: 0.03212, val_loss: 0.04039\n",
      "Epoch 27/500 - train_loss: 0.03078, val_loss: 0.03931\n",
      "Epoch 28/500 - train_loss: 0.02952, val_loss: 0.03825\n",
      "Epoch 29/500 - train_loss: 0.02840, val_loss: 0.03731\n",
      "Epoch 30/500 - train_loss: 0.02751, val_loss: 0.03655\n",
      "Epoch 31/500 - train_loss: 0.02688, val_loss: 0.03599\n",
      "Epoch 32/500 - train_loss: 0.02650, val_loss: 0.03562\n",
      "Epoch 33/500 - train_loss: 0.02629, val_loss: 0.03538\n",
      "Epoch 34/500 - train_loss: 0.02621, val_loss: 0.03524\n",
      "Epoch 35/500 - train_loss: 0.02625, val_loss: 0.03516\n",
      "Epoch 36/500 - train_loss: 0.02636, val_loss: 0.03510\n",
      "Epoch 37/500 - train_loss: 0.02645, val_loss: 0.03500\n",
      "Epoch 38/500 - train_loss: 0.02647, val_loss: 0.03482\n",
      "Epoch 39/500 - train_loss: 0.02640, val_loss: 0.03454\n",
      "Epoch 40/500 - train_loss: 0.02623, val_loss: 0.03416\n",
      "Epoch 41/500 - train_loss: 0.02594, val_loss: 0.03368\n",
      "Epoch 42/500 - train_loss: 0.02554, val_loss: 0.03311\n",
      "Epoch 43/500 - train_loss: 0.02507, val_loss: 0.03249\n",
      "Epoch 44/500 - train_loss: 0.02459, val_loss: 0.03188\n",
      "Epoch 45/500 - train_loss: 0.02413, val_loss: 0.03130\n",
      "Epoch 46/500 - train_loss: 0.02370, val_loss: 0.03076\n",
      "Epoch 47/500 - train_loss: 0.02331, val_loss: 0.03025\n",
      "Epoch 48/500 - train_loss: 0.02296, val_loss: 0.02977\n",
      "Epoch 49/500 - train_loss: 0.02265, val_loss: 0.02932\n",
      "Epoch 50/500 - train_loss: 0.02239, val_loss: 0.02892\n",
      "Epoch 51/500 - train_loss: 0.02218, val_loss: 0.02857\n",
      "Epoch 52/500 - train_loss: 0.02203, val_loss: 0.02825\n",
      "Epoch 53/500 - train_loss: 0.02189, val_loss: 0.02797\n",
      "Epoch 54/500 - train_loss: 0.02176, val_loss: 0.02769\n",
      "Epoch 55/500 - train_loss: 0.02160, val_loss: 0.02738\n",
      "Epoch 56/500 - train_loss: 0.02139, val_loss: 0.02703\n",
      "Epoch 57/500 - train_loss: 0.02114, val_loss: 0.02664\n",
      "Epoch 58/500 - train_loss: 0.02085, val_loss: 0.02622\n",
      "Epoch 59/500 - train_loss: 0.02054, val_loss: 0.02578\n",
      "Epoch 60/500 - train_loss: 0.02023, val_loss: 0.02534\n",
      "Epoch 61/500 - train_loss: 0.01992, val_loss: 0.02491\n",
      "Epoch 62/500 - train_loss: 0.01963, val_loss: 0.02450\n",
      "Epoch 63/500 - train_loss: 0.01935, val_loss: 0.02411\n",
      "Epoch 64/500 - train_loss: 0.01908, val_loss: 0.02374\n",
      "Epoch 65/500 - train_loss: 0.01882, val_loss: 0.02337\n",
      "Epoch 66/500 - train_loss: 0.01856, val_loss: 0.02302\n",
      "Epoch 67/500 - train_loss: 0.01830, val_loss: 0.02267\n",
      "Epoch 68/500 - train_loss: 0.01803, val_loss: 0.02231\n",
      "Epoch 69/500 - train_loss: 0.01775, val_loss: 0.02193\n",
      "Epoch 70/500 - train_loss: 0.01745, val_loss: 0.02154\n",
      "Epoch 71/500 - train_loss: 0.01714, val_loss: 0.02114\n",
      "Epoch 72/500 - train_loss: 0.01682, val_loss: 0.02074\n",
      "Epoch 73/500 - train_loss: 0.01649, val_loss: 0.02034\n",
      "Epoch 74/500 - train_loss: 0.01618, val_loss: 0.01995\n",
      "Epoch 75/500 - train_loss: 0.01587, val_loss: 0.01957\n",
      "Epoch 76/500 - train_loss: 0.01558, val_loss: 0.01921\n",
      "Epoch 77/500 - train_loss: 0.01530, val_loss: 0.01887\n",
      "Epoch 78/500 - train_loss: 0.01502, val_loss: 0.01853\n",
      "Epoch 79/500 - train_loss: 0.01475, val_loss: 0.01819\n",
      "Epoch 80/500 - train_loss: 0.01448, val_loss: 0.01784\n",
      "Epoch 81/500 - train_loss: 0.01420, val_loss: 0.01749\n",
      "Epoch 82/500 - train_loss: 0.01393, val_loss: 0.01714\n",
      "Epoch 83/500 - train_loss: 0.01366, val_loss: 0.01680\n",
      "Epoch 84/500 - train_loss: 0.01341, val_loss: 0.01646\n",
      "Epoch 85/500 - train_loss: 0.01316, val_loss: 0.01613\n",
      "Epoch 86/500 - train_loss: 0.01293, val_loss: 0.01581\n",
      "Epoch 87/500 - train_loss: 0.01271, val_loss: 0.01551\n",
      "Epoch 88/500 - train_loss: 0.01249, val_loss: 0.01522\n",
      "Epoch 89/500 - train_loss: 0.01229, val_loss: 0.01494\n",
      "Epoch 90/500 - train_loss: 0.01208, val_loss: 0.01467\n",
      "Epoch 91/500 - train_loss: 0.01188, val_loss: 0.01441\n",
      "Epoch 92/500 - train_loss: 0.01169, val_loss: 0.01416\n",
      "Epoch 93/500 - train_loss: 0.01151, val_loss: 0.01392\n",
      "Epoch 94/500 - train_loss: 0.01133, val_loss: 0.01370\n",
      "Epoch 95/500 - train_loss: 0.01117, val_loss: 0.01348\n",
      "Epoch 96/500 - train_loss: 0.01101, val_loss: 0.01328\n",
      "Epoch 97/500 - train_loss: 0.01087, val_loss: 0.01308\n",
      "Epoch 98/500 - train_loss: 0.01072, val_loss: 0.01289\n",
      "Epoch 99/500 - train_loss: 0.01058, val_loss: 0.01270\n",
      "Epoch 100/500 - train_loss: 0.01045, val_loss: 0.01251\n",
      "Epoch 101/500 - train_loss: 0.01032, val_loss: 0.01234\n",
      "Epoch 102/500 - train_loss: 0.01020, val_loss: 0.01217\n",
      "Epoch 103/500 - train_loss: 0.01008, val_loss: 0.01201\n",
      "Epoch 104/500 - train_loss: 0.00997, val_loss: 0.01186\n",
      "Epoch 105/500 - train_loss: 0.00987, val_loss: 0.01172\n",
      "Epoch 106/500 - train_loss: 0.00976, val_loss: 0.01157\n",
      "Epoch 107/500 - train_loss: 0.00966, val_loss: 0.01143\n",
      "Epoch 108/500 - train_loss: 0.00956, val_loss: 0.01129\n",
      "Epoch 109/500 - train_loss: 0.00947, val_loss: 0.01116\n",
      "Epoch 110/500 - train_loss: 0.00937, val_loss: 0.01102\n",
      "Epoch 111/500 - train_loss: 0.00928, val_loss: 0.01089\n",
      "Epoch 112/500 - train_loss: 0.00919, val_loss: 0.01076\n",
      "Epoch 113/500 - train_loss: 0.00911, val_loss: 0.01063\n",
      "Epoch 114/500 - train_loss: 0.00902, val_loss: 0.01051\n",
      "Epoch 115/500 - train_loss: 0.00894, val_loss: 0.01039\n",
      "Epoch 116/500 - train_loss: 0.00886, val_loss: 0.01027\n",
      "Epoch 117/500 - train_loss: 0.00878, val_loss: 0.01016\n",
      "Epoch 118/500 - train_loss: 0.00870, val_loss: 0.01005\n",
      "Epoch 119/500 - train_loss: 0.00863, val_loss: 0.00995\n",
      "Epoch 120/500 - train_loss: 0.00856, val_loss: 0.00984\n",
      "Epoch 121/500 - train_loss: 0.00849, val_loss: 0.00974\n",
      "Epoch 122/500 - train_loss: 0.00842, val_loss: 0.00965\n",
      "Epoch 123/500 - train_loss: 0.00835, val_loss: 0.00955\n",
      "Epoch 124/500 - train_loss: 0.00829, val_loss: 0.00946\n",
      "Epoch 125/500 - train_loss: 0.00823, val_loss: 0.00937\n",
      "Epoch 126/500 - train_loss: 0.00817, val_loss: 0.00928\n",
      "Epoch 127/500 - train_loss: 0.00812, val_loss: 0.00920\n",
      "Epoch 128/500 - train_loss: 0.00807, val_loss: 0.00912\n",
      "Epoch 129/500 - train_loss: 0.00802, val_loss: 0.00905\n",
      "Epoch 130/500 - train_loss: 0.00797, val_loss: 0.00898\n",
      "Epoch 131/500 - train_loss: 0.00792, val_loss: 0.00892\n",
      "Epoch 132/500 - train_loss: 0.00788, val_loss: 0.00886\n",
      "Epoch 133/500 - train_loss: 0.00784, val_loss: 0.00881\n",
      "Epoch 134/500 - train_loss: 0.00780, val_loss: 0.00876\n",
      "Epoch 135/500 - train_loss: 0.00777, val_loss: 0.00872\n",
      "Epoch 136/500 - train_loss: 0.00773, val_loss: 0.00868\n",
      "Epoch 137/500 - train_loss: 0.00770, val_loss: 0.00863\n",
      "Epoch 138/500 - train_loss: 0.00767, val_loss: 0.00859\n",
      "Epoch 139/500 - train_loss: 0.00764, val_loss: 0.00856\n",
      "Epoch 140/500 - train_loss: 0.00761, val_loss: 0.00852\n",
      "Epoch 141/500 - train_loss: 0.00759, val_loss: 0.00849\n",
      "Epoch 142/500 - train_loss: 0.00756, val_loss: 0.00845\n",
      "Epoch 143/500 - train_loss: 0.00754, val_loss: 0.00842\n",
      "Epoch 144/500 - train_loss: 0.00751, val_loss: 0.00840\n",
      "Epoch 145/500 - train_loss: 0.00749, val_loss: 0.00837\n",
      "Epoch 146/500 - train_loss: 0.00747, val_loss: 0.00834\n",
      "Epoch 147/500 - train_loss: 0.00745, val_loss: 0.00832\n",
      "Epoch 148/500 - train_loss: 0.00743, val_loss: 0.00829\n",
      "Epoch 149/500 - train_loss: 0.00741, val_loss: 0.00827\n",
      "Epoch 150/500 - train_loss: 0.00739, val_loss: 0.00825\n",
      "Epoch 151/500 - train_loss: 0.00737, val_loss: 0.00822\n",
      "Epoch 152/500 - train_loss: 0.00735, val_loss: 0.00820\n",
      "Epoch 153/500 - train_loss: 0.00733, val_loss: 0.00819\n",
      "Epoch 154/500 - train_loss: 0.00732, val_loss: 0.00817\n",
      "Epoch 155/500 - train_loss: 0.00730, val_loss: 0.00815\n",
      "Epoch 156/500 - train_loss: 0.00728, val_loss: 0.00813\n",
      "Epoch 157/500 - train_loss: 0.00727, val_loss: 0.00812\n",
      "Epoch 158/500 - train_loss: 0.00725, val_loss: 0.00810\n",
      "Epoch 159/500 - train_loss: 0.00724, val_loss: 0.00809\n",
      "Epoch 160/500 - train_loss: 0.00722, val_loss: 0.00807\n",
      "Epoch 161/500 - train_loss: 0.00721, val_loss: 0.00806\n",
      "Epoch 162/500 - train_loss: 0.00720, val_loss: 0.00804\n",
      "Epoch 163/500 - train_loss: 0.00719, val_loss: 0.00803\n",
      "Epoch 164/500 - train_loss: 0.00717, val_loss: 0.00801\n",
      "Epoch 165/500 - train_loss: 0.00716, val_loss: 0.00800\n",
      "Epoch 166/500 - train_loss: 0.00715, val_loss: 0.00799\n",
      "Epoch 167/500 - train_loss: 0.00714, val_loss: 0.00798\n",
      "Epoch 168/500 - train_loss: 0.00713, val_loss: 0.00797\n",
      "Epoch 169/500 - train_loss: 0.00712, val_loss: 0.00796\n",
      "Epoch 170/500 - train_loss: 0.00711, val_loss: 0.00795\n",
      "Epoch 171/500 - train_loss: 0.00710, val_loss: 0.00794\n",
      "Epoch 172/500 - train_loss: 0.00709, val_loss: 0.00793\n",
      "Epoch 173/500 - train_loss: 0.00708, val_loss: 0.00792\n",
      "Epoch 174/500 - train_loss: 0.00708, val_loss: 0.00790\n",
      "Epoch 175/500 - train_loss: 0.00707, val_loss: 0.00789\n",
      "Epoch 176/500 - train_loss: 0.00706, val_loss: 0.00788\n",
      "Epoch 177/500 - train_loss: 0.00705, val_loss: 0.00787\n",
      "Epoch 178/500 - train_loss: 0.00705, val_loss: 0.00786\n",
      "Epoch 179/500 - train_loss: 0.00704, val_loss: 0.00786\n",
      "Epoch 180/500 - train_loss: 0.00703, val_loss: 0.00785\n",
      "Epoch 181/500 - train_loss: 0.00703, val_loss: 0.00784\n",
      "Epoch 182/500 - train_loss: 0.00702, val_loss: 0.00783\n",
      "Epoch 183/500 - train_loss: 0.00701, val_loss: 0.00782\n",
      "Epoch 184/500 - train_loss: 0.00701, val_loss: 0.00781\n",
      "Epoch 185/500 - train_loss: 0.00700, val_loss: 0.00780\n",
      "Epoch 186/500 - train_loss: 0.00700, val_loss: 0.00779\n",
      "Epoch 187/500 - train_loss: 0.00699, val_loss: 0.00778\n",
      "Epoch 188/500 - train_loss: 0.00699, val_loss: 0.00777\n",
      "Epoch 189/500 - train_loss: 0.00698, val_loss: 0.00777\n",
      "Epoch 190/500 - train_loss: 0.00698, val_loss: 0.00776\n",
      "Epoch 191/500 - train_loss: 0.00697, val_loss: 0.00775\n",
      "Epoch 192/500 - train_loss: 0.00697, val_loss: 0.00775\n",
      "Epoch 193/500 - train_loss: 0.00696, val_loss: 0.00774\n",
      "Epoch 194/500 - train_loss: 0.00696, val_loss: 0.00773\n",
      "Epoch 195/500 - train_loss: 0.00696, val_loss: 0.00773\n",
      "Epoch 196/500 - train_loss: 0.00695, val_loss: 0.00772\n",
      "Epoch 197/500 - train_loss: 0.00695, val_loss: 0.00771\n",
      "Epoch 198/500 - train_loss: 0.00694, val_loss: 0.00771\n",
      "Epoch 199/500 - train_loss: 0.00694, val_loss: 0.00770\n",
      "Epoch 200/500 - train_loss: 0.00694, val_loss: 0.00770\n",
      "Epoch 201/500 - train_loss: 0.00693, val_loss: 0.00769\n",
      "Epoch 202/500 - train_loss: 0.00693, val_loss: 0.00769\n",
      "Epoch 203/500 - train_loss: 0.00693, val_loss: 0.00768\n",
      "Epoch 204/500 - train_loss: 0.00693, val_loss: 0.00768\n",
      "Epoch 205/500 - train_loss: 0.00692, val_loss: 0.00767\n",
      "Epoch 206/500 - train_loss: 0.00692, val_loss: 0.00767\n",
      "Epoch 207/500 - train_loss: 0.00692, val_loss: 0.00766\n",
      "Epoch 208/500 - train_loss: 0.00692, val_loss: 0.00766\n",
      "Epoch 209/500 - train_loss: 0.00691, val_loss: 0.00765\n",
      "Epoch 210/500 - train_loss: 0.00691, val_loss: 0.00765\n",
      "Epoch 211/500 - train_loss: 0.00691, val_loss: 0.00764\n",
      "Epoch 212/500 - train_loss: 0.00691, val_loss: 0.00764\n",
      "Epoch 213/500 - train_loss: 0.00690, val_loss: 0.00763\n",
      "Epoch 214/500 - train_loss: 0.00690, val_loss: 0.00763\n",
      "Epoch 215/500 - train_loss: 0.00690, val_loss: 0.00763\n",
      "Epoch 216/500 - train_loss: 0.00690, val_loss: 0.00762\n",
      "Epoch 217/500 - train_loss: 0.00690, val_loss: 0.00762\n",
      "Epoch 218/500 - train_loss: 0.00689, val_loss: 0.00761\n",
      "Epoch 219/500 - train_loss: 0.00689, val_loss: 0.00761\n",
      "Epoch 220/500 - train_loss: 0.00689, val_loss: 0.00761\n",
      "Epoch 221/500 - train_loss: 0.00689, val_loss: 0.00760\n",
      "Epoch 222/500 - train_loss: 0.00689, val_loss: 0.00760\n",
      "Epoch 223/500 - train_loss: 0.00689, val_loss: 0.00759\n",
      "Epoch 224/500 - train_loss: 0.00688, val_loss: 0.00759\n",
      "Epoch 225/500 - train_loss: 0.00688, val_loss: 0.00759\n",
      "Epoch 226/500 - train_loss: 0.00688, val_loss: 0.00758\n",
      "Epoch 227/500 - train_loss: 0.00688, val_loss: 0.00758\n",
      "Epoch 228/500 - train_loss: 0.00688, val_loss: 0.00758\n",
      "Epoch 229/500 - train_loss: 0.00688, val_loss: 0.00757\n",
      "Epoch 230/500 - train_loss: 0.00688, val_loss: 0.00757\n",
      "Epoch 231/500 - train_loss: 0.00688, val_loss: 0.00757\n",
      "Epoch 232/500 - train_loss: 0.00687, val_loss: 0.00756\n",
      "Epoch 233/500 - train_loss: 0.00687, val_loss: 0.00756\n",
      "Epoch 234/500 - train_loss: 0.00687, val_loss: 0.00756\n",
      "Epoch 235/500 - train_loss: 0.00687, val_loss: 0.00755\n",
      "Epoch 236/500 - train_loss: 0.00687, val_loss: 0.00755\n",
      "Epoch 237/500 - train_loss: 0.00687, val_loss: 0.00755\n",
      "Epoch 238/500 - train_loss: 0.00687, val_loss: 0.00755\n",
      "Epoch 239/500 - train_loss: 0.00687, val_loss: 0.00754\n",
      "Epoch 240/500 - train_loss: 0.00687, val_loss: 0.00754\n",
      "Epoch 241/500 - train_loss: 0.00686, val_loss: 0.00754\n",
      "Epoch 242/500 - train_loss: 0.00686, val_loss: 0.00753\n",
      "Epoch 243/500 - train_loss: 0.00686, val_loss: 0.00753\n",
      "Epoch 244/500 - train_loss: 0.00686, val_loss: 0.00753\n",
      "Epoch 245/500 - train_loss: 0.00686, val_loss: 0.00753\n",
      "Epoch 246/500 - train_loss: 0.00686, val_loss: 0.00752\n",
      "Epoch 247/500 - train_loss: 0.00686, val_loss: 0.00752\n",
      "Epoch 248/500 - train_loss: 0.00686, val_loss: 0.00752\n",
      "Epoch 249/500 - train_loss: 0.00686, val_loss: 0.00751\n",
      "Epoch 250/500 - train_loss: 0.00686, val_loss: 0.00751\n",
      "Epoch 251/500 - train_loss: 0.00686, val_loss: 0.00751\n",
      "Epoch 252/500 - train_loss: 0.00686, val_loss: 0.00751\n",
      "Epoch 253/500 - train_loss: 0.00685, val_loss: 0.00750\n",
      "Epoch 254/500 - train_loss: 0.00685, val_loss: 0.00750\n",
      "Epoch 255/500 - train_loss: 0.00685, val_loss: 0.00750\n",
      "Epoch 256/500 - train_loss: 0.00685, val_loss: 0.00750\n",
      "Epoch 257/500 - train_loss: 0.00685, val_loss: 0.00749\n",
      "Epoch 258/500 - train_loss: 0.00685, val_loss: 0.00749\n",
      "Epoch 259/500 - train_loss: 0.00685, val_loss: 0.00749\n",
      "Epoch 260/500 - train_loss: 0.00685, val_loss: 0.00749\n",
      "Epoch 261/500 - train_loss: 0.00685, val_loss: 0.00748\n",
      "Epoch 262/500 - train_loss: 0.00685, val_loss: 0.00748\n",
      "Epoch 263/500 - train_loss: 0.00685, val_loss: 0.00748\n",
      "Epoch 264/500 - train_loss: 0.00685, val_loss: 0.00748\n",
      "Epoch 265/500 - train_loss: 0.00685, val_loss: 0.00747\n",
      "Epoch 266/500 - train_loss: 0.00685, val_loss: 0.00747\n",
      "Epoch 267/500 - train_loss: 0.00685, val_loss: 0.00747\n",
      "Epoch 268/500 - train_loss: 0.00685, val_loss: 0.00747\n",
      "Epoch 269/500 - train_loss: 0.00684, val_loss: 0.00747\n",
      "Epoch 270/500 - train_loss: 0.00684, val_loss: 0.00746\n",
      "Epoch 271/500 - train_loss: 0.00684, val_loss: 0.00746\n",
      "Epoch 272/500 - train_loss: 0.00684, val_loss: 0.00746\n",
      "Epoch 273/500 - train_loss: 0.00684, val_loss: 0.00746\n",
      "Epoch 274/500 - train_loss: 0.00684, val_loss: 0.00745\n",
      "Epoch 275/500 - train_loss: 0.00684, val_loss: 0.00745\n",
      "Epoch 276/500 - train_loss: 0.00684, val_loss: 0.00745\n",
      "Epoch 277/500 - train_loss: 0.00684, val_loss: 0.00745\n",
      "Epoch 278/500 - train_loss: 0.00684, val_loss: 0.00745\n",
      "Epoch 279/500 - train_loss: 0.00684, val_loss: 0.00744\n",
      "Epoch 280/500 - train_loss: 0.00684, val_loss: 0.00744\n",
      "Epoch 281/500 - train_loss: 0.00684, val_loss: 0.00744\n",
      "Epoch 282/500 - train_loss: 0.00684, val_loss: 0.00744\n",
      "Epoch 283/500 - train_loss: 0.00684, val_loss: 0.00744\n",
      "Epoch 284/500 - train_loss: 0.00684, val_loss: 0.00743\n",
      "Epoch 285/500 - train_loss: 0.00684, val_loss: 0.00743\n",
      "Epoch 286/500 - train_loss: 0.00684, val_loss: 0.00743\n",
      "Epoch 287/500 - train_loss: 0.00683, val_loss: 0.00743\n",
      "Epoch 288/500 - train_loss: 0.00683, val_loss: 0.00743\n",
      "Epoch 289/500 - train_loss: 0.00683, val_loss: 0.00742\n",
      "Epoch 290/500 - train_loss: 0.00683, val_loss: 0.00742\n",
      "Epoch 291/500 - train_loss: 0.00683, val_loss: 0.00742\n",
      "Epoch 292/500 - train_loss: 0.00683, val_loss: 0.00742\n",
      "Epoch 293/500 - train_loss: 0.00683, val_loss: 0.00742\n",
      "Epoch 294/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 295/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 296/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 297/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 298/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 299/500 - train_loss: 0.00683, val_loss: 0.00741\n",
      "Epoch 300/500 - train_loss: 0.00684, val_loss: 0.00741\n",
      "Epoch 301/500 - train_loss: 0.00687, val_loss: 0.00743\n",
      "Epoch 302/500 - train_loss: 0.00687, val_loss: 0.00742\n",
      "Epoch 303/500 - train_loss: 0.00683, val_loss: 0.00740\n",
      "Epoch 304/500 - train_loss: 0.00685, val_loss: 0.00741\n",
      "Epoch 305/500 - train_loss: 0.00685, val_loss: 0.00741\n",
      "Epoch 306/500 - train_loss: 0.00683, val_loss: 0.00740\n",
      "Epoch 307/500 - train_loss: 0.00685, val_loss: 0.00741\n",
      "Epoch 308/500 - train_loss: 0.00683, val_loss: 0.00740\n",
      "Epoch 309/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 310/500 - train_loss: 0.00684, val_loss: 0.00740\n",
      "Epoch 311/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 312/500 - train_loss: 0.00684, val_loss: 0.00739\n",
      "Epoch 313/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 314/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 315/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 316/500 - train_loss: 0.00683, val_loss: 0.00739\n",
      "Epoch 317/500 - train_loss: 0.00684, val_loss: 0.00740\n",
      "Epoch 318/500 - train_loss: 0.00684, val_loss: 0.00740\n",
      "Epoch 319/500 - train_loss: 0.00685, val_loss: 0.00740\n",
      "Epoch 320/500 - train_loss: 0.00684, val_loss: 0.00739\n",
      "Epoch 321/500 - train_loss: 0.00683, val_loss: 0.00738\n",
      "Epoch 322/500 - train_loss: 0.00682, val_loss: 0.00738\n",
      "Epoch 323/500 - train_loss: 0.00683, val_loss: 0.00738\n",
      "Epoch 324/500 - train_loss: 0.00684, val_loss: 0.00739\n",
      "Epoch 325/500 - train_loss: 0.00683, val_loss: 0.00738\n",
      "Epoch 326/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 327/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 328/500 - train_loss: 0.00683, val_loss: 0.00738\n",
      "Epoch 329/500 - train_loss: 0.00683, val_loss: 0.00737\n",
      "Epoch 330/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 331/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 332/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 333/500 - train_loss: 0.00682, val_loss: 0.00737\n",
      "Epoch 334/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 335/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 336/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 337/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 338/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 339/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 340/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 341/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 342/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 343/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 344/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 345/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 346/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 347/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 348/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 349/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 350/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 351/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 352/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 353/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 354/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 355/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 356/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 357/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 358/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 359/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 360/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 361/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 362/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 363/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 364/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 365/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 366/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 367/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 368/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 369/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 370/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 371/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 372/500 - train_loss: 0.00682, val_loss: 0.00735\n",
      "Epoch 373/500 - train_loss: 0.00681, val_loss: 0.00736\n",
      "Epoch 374/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 375/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 376/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 377/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 378/500 - train_loss: 0.00682, val_loss: 0.00736\n",
      "Epoch 379/500 - train_loss: 0.00682, val_loss: 0.00734\n",
      "Epoch 380/500 - train_loss: 0.00681, val_loss: 0.00735\n",
      "Epoch 381/500 - train_loss: 0.00680, val_loss: 0.00734\n",
      "Epoch 382/500 - train_loss: 0.00680, val_loss: 0.00733\n",
      "Epoch 383/500 - train_loss: 0.00680, val_loss: 0.00734\n",
      "Epoch 384/500 - train_loss: 0.00681, val_loss: 0.00734\n",
      "Epoch 385/500 - train_loss: 0.00680, val_loss: 0.00734\n",
      "Epoch 386/500 - train_loss: 0.00680, val_loss: 0.00734\n",
      "Epoch 387/500 - train_loss: 0.00680, val_loss: 0.00733\n",
      "Epoch 388/500 - train_loss: 0.00680, val_loss: 0.00734\n",
      "Stopping early at epoch 389.\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    x_val=X_val,\n",
    "    y_val=y_val,\n",
    "    num_epochs=500,\n",
    "    learning_rate=0.03,\n",
    "    early_stopping=EarlyStopping(patience=25)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:25.156792300Z",
     "start_time": "2024-02-01T12:15:10.205158600Z"
    }
   },
   "id": "41e6bb9f3a8c5f1d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84         9\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.70      0.67      0.68        23\n",
      "weighted avg       0.70      0.70      0.69        23\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['setosa', 'versicolor', 'virginica'])\n",
    "disp.plot(cmap='Greens')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:26.372172100Z",
     "start_time": "2024-02-01T12:15:26.135191700Z"
    }
   },
   "id": "eabe332aeff7b959",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have successfully trained a pretty decent Quantum Neural Network (QNN) using a straightforward and efficient approach. Our next objective is to further enhance the performance and efficiency of our QNN. To achieve this, we will be implementing the data reuploading technique.\n",
    "\n",
    "Data reuploading is a powerful strategy that allows for repeated encoding of classical data into quantum states within a single quantum circuit. This technique effectively enhances the capacity of the quantum model to capture complex patterns and relationships in the data, leading to potentially improved performance in tasks like classification and regression.\n",
    "\n",
    "We will also integrate JAX as the computational backend."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ebd0369b0b8624"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set backend to JAX for CPU computations acceleration\n",
    "device_manager.update(device='cpu.jax')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:30.429791800Z",
     "start_time": "2024-02-01T12:15:30.426721200Z"
    }
   },
   "id": "7559d42a15d2678d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Number of qubits corresponding to the number of features in the dataset\n",
    "n_qubits = 4\n",
    "\n",
    "# AngleEmbedding encodes the number of features equal to number of qubits\n",
    "feature_map = AngleEmbedding(\n",
    "    n_qubits=n_qubits\n",
    ")\n",
    "\n",
    "# TwoLocal ansatz with custom entanglement scheme\n",
    "ansatz = TwoLocal(\n",
    "    n_qubits=n_qubits,\n",
    "    entanglement=[[0, 2], [1, 3], [2, 0], [3, 1]],\n",
    "    skip_last_rotations=False,\n",
    "    reps=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:31.370289Z",
     "start_time": "2024-02-01T12:15:31.367284100Z"
    }
   },
   "id": "b9df94809494ef79",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create QNNClassifier model with defined ansatz and feature map\n",
    "# Use data reuploading technique by setting data_reuploading to True\n",
    "model = QNNClassifier(\n",
    "    n_qubits=n_qubits,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    data_reuploading=True,\n",
    "    layers_num=3,\n",
    "    classes_num=3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:32.366988900Z",
     "start_time": "2024-02-01T12:15:32.324798Z"
    }
   },
   "id": "304c3d51266ca55f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)──RY(0.10)─╭●────╭X─────||──RY(0.05)─╭AngleEmbedding(M0)──RY(0.04)─╭●────╭X\n",
      "1: ─├AngleEmbedding(M0)──RY(0.07)─│──╭●─│──╭X──||──RY(0.08)─├AngleEmbedding(M0)──RY(0.09)─│──╭●─│─\n",
      "2: ─├AngleEmbedding(M0)──RY(0.05)─╰X─│──╰●─│───||──RY(0.03)─├AngleEmbedding(M0)──RY(0.04)─╰X─│──╰●\n",
      "3: ─╰AngleEmbedding(M0)──RY(0.03)────╰X────╰●──||──RY(0.06)─╰AngleEmbedding(M0)──RY(0.02)────╰X───\n",
      "\n",
      "──────||──RY(0.09)─╭AngleEmbedding(M0)──RY(0.02)─╭●────╭X─────||──RY(0.03)─┤  \n",
      "──╭X──||──RY(0.02)─├AngleEmbedding(M0)──RY(0.04)─│──╭●─│──╭X──||──RY(0.05)─┤  \n",
      "──│───||──RY(0.10)─├AngleEmbedding(M0)──RY(0.09)─╰X─│──╰●─│───||──RY(0.01)─┤  \n",
      "──╰●──||──RY(0.01)─╰AngleEmbedding(M0)──RY(0.02)────╰X────╰●──||──RY(0.05)─┤  \n",
      "M0 = \n",
      "[[-0.47969533  0.74562144 -0.12913455 -0.52297891]]\n"
     ]
    }
   ],
   "source": [
    "model.draw_circuit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:32.959032400Z",
     "start_time": "2024-02-01T12:15:32.949005500Z"
    }
   },
   "id": "acefd34ea1915e2b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - train_loss: 0.85594, val_loss: 0.72694\n",
      "Epoch 2/500 - train_loss: 0.77104, val_loss: 0.65428\n",
      "Epoch 3/500 - train_loss: 0.70050, val_loss: 0.59336\n",
      "Epoch 4/500 - train_loss: 0.64020, val_loss: 0.54136\n",
      "Epoch 5/500 - train_loss: 0.58780, val_loss: 0.49646\n",
      "Epoch 6/500 - train_loss: 0.54174, val_loss: 0.45733\n",
      "Epoch 7/500 - train_loss: 0.50089, val_loss: 0.42300\n",
      "Epoch 8/500 - train_loss: 0.46441, val_loss: 0.39266\n",
      "Epoch 9/500 - train_loss: 0.43163, val_loss: 0.36566\n",
      "Epoch 10/500 - train_loss: 0.40198, val_loss: 0.34146\n",
      "Epoch 11/500 - train_loss: 0.37500, val_loss: 0.31961\n",
      "Epoch 12/500 - train_loss: 0.35032, val_loss: 0.29973\n",
      "Epoch 13/500 - train_loss: 0.32761, val_loss: 0.28155\n",
      "Epoch 14/500 - train_loss: 0.30664, val_loss: 0.26482\n",
      "Epoch 15/500 - train_loss: 0.28720, val_loss: 0.24937\n",
      "Epoch 16/500 - train_loss: 0.26913, val_loss: 0.23504\n",
      "Epoch 17/500 - train_loss: 0.25230, val_loss: 0.22173\n",
      "Epoch 18/500 - train_loss: 0.23660, val_loss: 0.20932\n",
      "Epoch 19/500 - train_loss: 0.22194, val_loss: 0.19775\n",
      "Epoch 20/500 - train_loss: 0.20824, val_loss: 0.18694\n",
      "Epoch 21/500 - train_loss: 0.19544, val_loss: 0.17683\n",
      "Epoch 22/500 - train_loss: 0.18347, val_loss: 0.16737\n",
      "Epoch 23/500 - train_loss: 0.17228, val_loss: 0.15852\n",
      "Epoch 24/500 - train_loss: 0.16183, val_loss: 0.15024\n",
      "Epoch 25/500 - train_loss: 0.15207, val_loss: 0.14249\n",
      "Epoch 26/500 - train_loss: 0.14297, val_loss: 0.13524\n",
      "Epoch 27/500 - train_loss: 0.13449, val_loss: 0.12847\n",
      "Epoch 28/500 - train_loss: 0.12660, val_loss: 0.12215\n",
      "Epoch 29/500 - train_loss: 0.11927, val_loss: 0.11626\n",
      "Epoch 30/500 - train_loss: 0.11247, val_loss: 0.11078\n",
      "Epoch 31/500 - train_loss: 0.10617, val_loss: 0.10569\n",
      "Epoch 32/500 - train_loss: 0.10035, val_loss: 0.10095\n",
      "Epoch 33/500 - train_loss: 0.09498, val_loss: 0.09656\n",
      "Epoch 34/500 - train_loss: 0.09003, val_loss: 0.09249\n",
      "Epoch 35/500 - train_loss: 0.08548, val_loss: 0.08872\n",
      "Epoch 36/500 - train_loss: 0.08130, val_loss: 0.08523\n",
      "Epoch 37/500 - train_loss: 0.07745, val_loss: 0.08200\n",
      "Epoch 38/500 - train_loss: 0.07391, val_loss: 0.07900\n",
      "Epoch 39/500 - train_loss: 0.07066, val_loss: 0.07621\n",
      "Epoch 40/500 - train_loss: 0.06768, val_loss: 0.07362\n",
      "Epoch 41/500 - train_loss: 0.06492, val_loss: 0.07121\n",
      "Epoch 42/500 - train_loss: 0.06238, val_loss: 0.06897\n",
      "Epoch 43/500 - train_loss: 0.06004, val_loss: 0.06686\n",
      "Epoch 44/500 - train_loss: 0.05787, val_loss: 0.06489\n",
      "Epoch 45/500 - train_loss: 0.05586, val_loss: 0.06304\n",
      "Epoch 46/500 - train_loss: 0.05399, val_loss: 0.06131\n",
      "Epoch 47/500 - train_loss: 0.05226, val_loss: 0.05967\n",
      "Epoch 48/500 - train_loss: 0.05065, val_loss: 0.05813\n",
      "Epoch 49/500 - train_loss: 0.04915, val_loss: 0.05667\n",
      "Epoch 50/500 - train_loss: 0.04775, val_loss: 0.05528\n",
      "Epoch 51/500 - train_loss: 0.04645, val_loss: 0.05398\n",
      "Epoch 52/500 - train_loss: 0.04523, val_loss: 0.05273\n",
      "Epoch 53/500 - train_loss: 0.04409, val_loss: 0.05155\n",
      "Epoch 54/500 - train_loss: 0.04303, val_loss: 0.05043\n",
      "Epoch 55/500 - train_loss: 0.04203, val_loss: 0.04935\n",
      "Epoch 56/500 - train_loss: 0.04108, val_loss: 0.04832\n",
      "Epoch 57/500 - train_loss: 0.04019, val_loss: 0.04734\n",
      "Epoch 58/500 - train_loss: 0.03935, val_loss: 0.04639\n",
      "Epoch 59/500 - train_loss: 0.03854, val_loss: 0.04548\n",
      "Epoch 60/500 - train_loss: 0.03777, val_loss: 0.04460\n",
      "Epoch 61/500 - train_loss: 0.03703, val_loss: 0.04375\n",
      "Epoch 62/500 - train_loss: 0.03632, val_loss: 0.04293\n",
      "Epoch 63/500 - train_loss: 0.03564, val_loss: 0.04214\n",
      "Epoch 64/500 - train_loss: 0.03497, val_loss: 0.04137\n",
      "Epoch 65/500 - train_loss: 0.03433, val_loss: 0.04062\n",
      "Epoch 66/500 - train_loss: 0.03371, val_loss: 0.03989\n",
      "Epoch 67/500 - train_loss: 0.03310, val_loss: 0.03919\n",
      "Epoch 68/500 - train_loss: 0.03251, val_loss: 0.03851\n",
      "Epoch 69/500 - train_loss: 0.03194, val_loss: 0.03784\n",
      "Epoch 70/500 - train_loss: 0.03139, val_loss: 0.03720\n",
      "Epoch 71/500 - train_loss: 0.03085, val_loss: 0.03658\n",
      "Epoch 72/500 - train_loss: 0.03033, val_loss: 0.03597\n",
      "Epoch 73/500 - train_loss: 0.02983, val_loss: 0.03538\n",
      "Epoch 74/500 - train_loss: 0.02934, val_loss: 0.03481\n",
      "Epoch 75/500 - train_loss: 0.02887, val_loss: 0.03426\n",
      "Epoch 76/500 - train_loss: 0.02841, val_loss: 0.03372\n",
      "Epoch 77/500 - train_loss: 0.02798, val_loss: 0.03320\n",
      "Epoch 78/500 - train_loss: 0.02755, val_loss: 0.03270\n",
      "Epoch 79/500 - train_loss: 0.02714, val_loss: 0.03220\n",
      "Epoch 80/500 - train_loss: 0.02674, val_loss: 0.03172\n",
      "Epoch 81/500 - train_loss: 0.02635, val_loss: 0.03125\n",
      "Epoch 82/500 - train_loss: 0.02598, val_loss: 0.03080\n",
      "Epoch 83/500 - train_loss: 0.02561, val_loss: 0.03035\n",
      "Epoch 84/500 - train_loss: 0.02526, val_loss: 0.02991\n",
      "Epoch 85/500 - train_loss: 0.02491, val_loss: 0.02949\n",
      "Epoch 86/500 - train_loss: 0.02457, val_loss: 0.02907\n",
      "Epoch 87/500 - train_loss: 0.02424, val_loss: 0.02866\n",
      "Epoch 88/500 - train_loss: 0.02392, val_loss: 0.02826\n",
      "Epoch 89/500 - train_loss: 0.02361, val_loss: 0.02787\n",
      "Epoch 90/500 - train_loss: 0.02330, val_loss: 0.02749\n",
      "Epoch 91/500 - train_loss: 0.02300, val_loss: 0.02711\n",
      "Epoch 92/500 - train_loss: 0.02271, val_loss: 0.02674\n",
      "Epoch 93/500 - train_loss: 0.02242, val_loss: 0.02638\n",
      "Epoch 94/500 - train_loss: 0.02214, val_loss: 0.02602\n",
      "Epoch 95/500 - train_loss: 0.02186, val_loss: 0.02567\n",
      "Epoch 96/500 - train_loss: 0.02159, val_loss: 0.02533\n",
      "Epoch 97/500 - train_loss: 0.02132, val_loss: 0.02499\n",
      "Epoch 98/500 - train_loss: 0.02106, val_loss: 0.02466\n",
      "Epoch 99/500 - train_loss: 0.02080, val_loss: 0.02434\n",
      "Epoch 100/500 - train_loss: 0.02055, val_loss: 0.02402\n",
      "Epoch 101/500 - train_loss: 0.02030, val_loss: 0.02371\n",
      "Epoch 102/500 - train_loss: 0.02006, val_loss: 0.02341\n",
      "Epoch 103/500 - train_loss: 0.01982, val_loss: 0.02311\n",
      "Epoch 104/500 - train_loss: 0.01958, val_loss: 0.02282\n",
      "Epoch 105/500 - train_loss: 0.01935, val_loss: 0.02253\n",
      "Epoch 106/500 - train_loss: 0.01912, val_loss: 0.02225\n",
      "Epoch 107/500 - train_loss: 0.01890, val_loss: 0.02197\n",
      "Epoch 108/500 - train_loss: 0.01867, val_loss: 0.02170\n",
      "Epoch 109/500 - train_loss: 0.01846, val_loss: 0.02143\n",
      "Epoch 110/500 - train_loss: 0.01824, val_loss: 0.02117\n",
      "Epoch 111/500 - train_loss: 0.01804, val_loss: 0.02092\n",
      "Epoch 112/500 - train_loss: 0.01783, val_loss: 0.02066\n",
      "Epoch 113/500 - train_loss: 0.01763, val_loss: 0.02042\n",
      "Epoch 114/500 - train_loss: 0.01743, val_loss: 0.02017\n",
      "Epoch 115/500 - train_loss: 0.01723, val_loss: 0.01993\n",
      "Epoch 116/500 - train_loss: 0.01704, val_loss: 0.01970\n",
      "Epoch 117/500 - train_loss: 0.01685, val_loss: 0.01947\n",
      "Epoch 118/500 - train_loss: 0.01666, val_loss: 0.01924\n",
      "Epoch 119/500 - train_loss: 0.01648, val_loss: 0.01902\n",
      "Epoch 120/500 - train_loss: 0.01630, val_loss: 0.01880\n",
      "Epoch 121/500 - train_loss: 0.01612, val_loss: 0.01859\n",
      "Epoch 122/500 - train_loss: 0.01595, val_loss: 0.01837\n",
      "Epoch 123/500 - train_loss: 0.01578, val_loss: 0.01816\n",
      "Epoch 124/500 - train_loss: 0.01561, val_loss: 0.01796\n",
      "Epoch 125/500 - train_loss: 0.01544, val_loss: 0.01776\n",
      "Epoch 126/500 - train_loss: 0.01528, val_loss: 0.01756\n",
      "Epoch 127/500 - train_loss: 0.01512, val_loss: 0.01736\n",
      "Epoch 128/500 - train_loss: 0.01496, val_loss: 0.01717\n",
      "Epoch 129/500 - train_loss: 0.01481, val_loss: 0.01698\n",
      "Epoch 130/500 - train_loss: 0.01465, val_loss: 0.01679\n",
      "Epoch 131/500 - train_loss: 0.01450, val_loss: 0.01661\n",
      "Epoch 132/500 - train_loss: 0.01436, val_loss: 0.01643\n",
      "Epoch 133/500 - train_loss: 0.01421, val_loss: 0.01625\n",
      "Epoch 134/500 - train_loss: 0.01407, val_loss: 0.01608\n",
      "Epoch 135/500 - train_loss: 0.01393, val_loss: 0.01590\n",
      "Epoch 136/500 - train_loss: 0.01379, val_loss: 0.01573\n",
      "Epoch 137/500 - train_loss: 0.01365, val_loss: 0.01557\n",
      "Epoch 138/500 - train_loss: 0.01352, val_loss: 0.01540\n",
      "Epoch 139/500 - train_loss: 0.01338, val_loss: 0.01524\n",
      "Epoch 140/500 - train_loss: 0.01325, val_loss: 0.01508\n",
      "Epoch 141/500 - train_loss: 0.01312, val_loss: 0.01492\n",
      "Epoch 142/500 - train_loss: 0.01300, val_loss: 0.01477\n",
      "Epoch 143/500 - train_loss: 0.01287, val_loss: 0.01462\n",
      "Epoch 144/500 - train_loss: 0.01275, val_loss: 0.01447\n",
      "Epoch 145/500 - train_loss: 0.01263, val_loss: 0.01432\n",
      "Epoch 146/500 - train_loss: 0.01251, val_loss: 0.01417\n",
      "Epoch 147/500 - train_loss: 0.01240, val_loss: 0.01403\n",
      "Epoch 148/500 - train_loss: 0.01228, val_loss: 0.01389\n",
      "Epoch 149/500 - train_loss: 0.01217, val_loss: 0.01375\n",
      "Epoch 150/500 - train_loss: 0.01206, val_loss: 0.01361\n",
      "Epoch 151/500 - train_loss: 0.01195, val_loss: 0.01347\n",
      "Epoch 152/500 - train_loss: 0.01184, val_loss: 0.01334\n",
      "Epoch 153/500 - train_loss: 0.01173, val_loss: 0.01321\n",
      "Epoch 154/500 - train_loss: 0.01163, val_loss: 0.01308\n",
      "Epoch 155/500 - train_loss: 0.01153, val_loss: 0.01295\n",
      "Epoch 156/500 - train_loss: 0.01142, val_loss: 0.01283\n",
      "Epoch 157/500 - train_loss: 0.01132, val_loss: 0.01270\n",
      "Epoch 158/500 - train_loss: 0.01123, val_loss: 0.01258\n",
      "Epoch 159/500 - train_loss: 0.01113, val_loss: 0.01246\n",
      "Epoch 160/500 - train_loss: 0.01103, val_loss: 0.01234\n",
      "Epoch 161/500 - train_loss: 0.01094, val_loss: 0.01223\n",
      "Epoch 162/500 - train_loss: 0.01085, val_loss: 0.01211\n",
      "Epoch 163/500 - train_loss: 0.01076, val_loss: 0.01200\n",
      "Epoch 164/500 - train_loss: 0.01067, val_loss: 0.01189\n",
      "Epoch 165/500 - train_loss: 0.01058, val_loss: 0.01178\n",
      "Epoch 166/500 - train_loss: 0.01049, val_loss: 0.01167\n",
      "Epoch 167/500 - train_loss: 0.01041, val_loss: 0.01156\n",
      "Epoch 168/500 - train_loss: 0.01032, val_loss: 0.01146\n",
      "Epoch 169/500 - train_loss: 0.01024, val_loss: 0.01135\n",
      "Epoch 170/500 - train_loss: 0.01016, val_loss: 0.01125\n",
      "Epoch 171/500 - train_loss: 0.01008, val_loss: 0.01115\n",
      "Epoch 172/500 - train_loss: 0.01000, val_loss: 0.01105\n",
      "Epoch 173/500 - train_loss: 0.00992, val_loss: 0.01095\n",
      "Epoch 174/500 - train_loss: 0.00984, val_loss: 0.01086\n",
      "Epoch 175/500 - train_loss: 0.00977, val_loss: 0.01076\n",
      "Epoch 176/500 - train_loss: 0.00969, val_loss: 0.01067\n",
      "Epoch 177/500 - train_loss: 0.00962, val_loss: 0.01058\n",
      "Epoch 178/500 - train_loss: 0.00954, val_loss: 0.01048\n",
      "Epoch 179/500 - train_loss: 0.00947, val_loss: 0.01039\n",
      "Epoch 180/500 - train_loss: 0.00940, val_loss: 0.01031\n",
      "Epoch 181/500 - train_loss: 0.00933, val_loss: 0.01022\n",
      "Epoch 182/500 - train_loss: 0.00926, val_loss: 0.01013\n",
      "Epoch 183/500 - train_loss: 0.00919, val_loss: 0.01005\n",
      "Epoch 184/500 - train_loss: 0.00913, val_loss: 0.00996\n",
      "Epoch 185/500 - train_loss: 0.00906, val_loss: 0.00988\n",
      "Epoch 186/500 - train_loss: 0.00900, val_loss: 0.00980\n",
      "Epoch 187/500 - train_loss: 0.00893, val_loss: 0.00972\n",
      "Epoch 188/500 - train_loss: 0.00887, val_loss: 0.00964\n",
      "Epoch 189/500 - train_loss: 0.00881, val_loss: 0.00956\n",
      "Epoch 190/500 - train_loss: 0.00874, val_loss: 0.00948\n",
      "Epoch 191/500 - train_loss: 0.00868, val_loss: 0.00941\n",
      "Epoch 192/500 - train_loss: 0.00862, val_loss: 0.00933\n",
      "Epoch 193/500 - train_loss: 0.00856, val_loss: 0.00926\n",
      "Epoch 194/500 - train_loss: 0.00850, val_loss: 0.00918\n",
      "Epoch 195/500 - train_loss: 0.00845, val_loss: 0.00911\n",
      "Epoch 196/500 - train_loss: 0.00839, val_loss: 0.00904\n",
      "Epoch 197/500 - train_loss: 0.00833, val_loss: 0.00897\n",
      "Epoch 198/500 - train_loss: 0.00828, val_loss: 0.00890\n",
      "Epoch 199/500 - train_loss: 0.00822, val_loss: 0.00883\n",
      "Epoch 200/500 - train_loss: 0.00817, val_loss: 0.00876\n",
      "Epoch 201/500 - train_loss: 0.00811, val_loss: 0.00869\n",
      "Epoch 202/500 - train_loss: 0.00806, val_loss: 0.00863\n",
      "Epoch 203/500 - train_loss: 0.00801, val_loss: 0.00856\n",
      "Epoch 204/500 - train_loss: 0.00796, val_loss: 0.00850\n",
      "Epoch 205/500 - train_loss: 0.00791, val_loss: 0.00843\n",
      "Epoch 206/500 - train_loss: 0.00786, val_loss: 0.00837\n",
      "Epoch 207/500 - train_loss: 0.00781, val_loss: 0.00831\n",
      "Epoch 208/500 - train_loss: 0.00776, val_loss: 0.00825\n",
      "Epoch 209/500 - train_loss: 0.00771, val_loss: 0.00819\n",
      "Epoch 210/500 - train_loss: 0.00766, val_loss: 0.00813\n",
      "Epoch 211/500 - train_loss: 0.00761, val_loss: 0.00807\n",
      "Epoch 212/500 - train_loss: 0.00756, val_loss: 0.00801\n",
      "Epoch 213/500 - train_loss: 0.00752, val_loss: 0.00795\n",
      "Epoch 214/500 - train_loss: 0.00747, val_loss: 0.00789\n",
      "Epoch 215/500 - train_loss: 0.00743, val_loss: 0.00784\n",
      "Epoch 216/500 - train_loss: 0.00738, val_loss: 0.00778\n",
      "Epoch 217/500 - train_loss: 0.00734, val_loss: 0.00773\n",
      "Epoch 218/500 - train_loss: 0.00729, val_loss: 0.00767\n",
      "Epoch 219/500 - train_loss: 0.00725, val_loss: 0.00762\n",
      "Epoch 220/500 - train_loss: 0.00721, val_loss: 0.00756\n",
      "Epoch 221/500 - train_loss: 0.00717, val_loss: 0.00751\n",
      "Epoch 222/500 - train_loss: 0.00712, val_loss: 0.00746\n",
      "Epoch 223/500 - train_loss: 0.00708, val_loss: 0.00741\n",
      "Epoch 224/500 - train_loss: 0.00704, val_loss: 0.00736\n",
      "Epoch 225/500 - train_loss: 0.00700, val_loss: 0.00731\n",
      "Epoch 226/500 - train_loss: 0.00696, val_loss: 0.00726\n",
      "Epoch 227/500 - train_loss: 0.00692, val_loss: 0.00721\n",
      "Epoch 228/500 - train_loss: 0.00688, val_loss: 0.00716\n",
      "Epoch 229/500 - train_loss: 0.00684, val_loss: 0.00711\n",
      "Epoch 230/500 - train_loss: 0.00680, val_loss: 0.00706\n",
      "Epoch 231/500 - train_loss: 0.00677, val_loss: 0.00702\n",
      "Epoch 232/500 - train_loss: 0.00673, val_loss: 0.00697\n",
      "Epoch 233/500 - train_loss: 0.00669, val_loss: 0.00692\n",
      "Epoch 234/500 - train_loss: 0.00665, val_loss: 0.00688\n",
      "Epoch 235/500 - train_loss: 0.00662, val_loss: 0.00683\n",
      "Epoch 236/500 - train_loss: 0.00658, val_loss: 0.00679\n",
      "Epoch 237/500 - train_loss: 0.00655, val_loss: 0.00674\n",
      "Epoch 238/500 - train_loss: 0.00651, val_loss: 0.00670\n",
      "Epoch 239/500 - train_loss: 0.00648, val_loss: 0.00666\n",
      "Epoch 240/500 - train_loss: 0.00644, val_loss: 0.00661\n",
      "Epoch 241/500 - train_loss: 0.00641, val_loss: 0.00657\n",
      "Epoch 242/500 - train_loss: 0.00637, val_loss: 0.00653\n",
      "Epoch 243/500 - train_loss: 0.00634, val_loss: 0.00649\n",
      "Epoch 244/500 - train_loss: 0.00631, val_loss: 0.00645\n",
      "Epoch 245/500 - train_loss: 0.00627, val_loss: 0.00641\n",
      "Epoch 246/500 - train_loss: 0.00624, val_loss: 0.00637\n",
      "Epoch 247/500 - train_loss: 0.00621, val_loss: 0.00633\n",
      "Epoch 248/500 - train_loss: 0.00618, val_loss: 0.00629\n",
      "Epoch 249/500 - train_loss: 0.00615, val_loss: 0.00625\n",
      "Epoch 250/500 - train_loss: 0.00611, val_loss: 0.00621\n",
      "Epoch 251/500 - train_loss: 0.00608, val_loss: 0.00617\n",
      "Epoch 252/500 - train_loss: 0.00605, val_loss: 0.00614\n",
      "Epoch 253/500 - train_loss: 0.00602, val_loss: 0.00610\n",
      "Epoch 254/500 - train_loss: 0.00599, val_loss: 0.00606\n",
      "Epoch 255/500 - train_loss: 0.00596, val_loss: 0.00603\n",
      "Epoch 256/500 - train_loss: 0.00593, val_loss: 0.00599\n",
      "Epoch 257/500 - train_loss: 0.00591, val_loss: 0.00596\n",
      "Epoch 258/500 - train_loss: 0.00588, val_loss: 0.00592\n",
      "Epoch 259/500 - train_loss: 0.00585, val_loss: 0.00589\n",
      "Epoch 260/500 - train_loss: 0.00582, val_loss: 0.00585\n",
      "Epoch 261/500 - train_loss: 0.00579, val_loss: 0.00582\n",
      "Epoch 262/500 - train_loss: 0.00577, val_loss: 0.00578\n",
      "Epoch 263/500 - train_loss: 0.00574, val_loss: 0.00575\n",
      "Epoch 264/500 - train_loss: 0.00571, val_loss: 0.00572\n",
      "Epoch 265/500 - train_loss: 0.00568, val_loss: 0.00568\n",
      "Epoch 266/500 - train_loss: 0.00566, val_loss: 0.00565\n",
      "Epoch 267/500 - train_loss: 0.00563, val_loss: 0.00562\n",
      "Epoch 268/500 - train_loss: 0.00561, val_loss: 0.00559\n",
      "Epoch 269/500 - train_loss: 0.00558, val_loss: 0.00556\n",
      "Epoch 270/500 - train_loss: 0.00555, val_loss: 0.00552\n",
      "Epoch 271/500 - train_loss: 0.00553, val_loss: 0.00549\n",
      "Epoch 272/500 - train_loss: 0.00550, val_loss: 0.00546\n",
      "Epoch 273/500 - train_loss: 0.00548, val_loss: 0.00543\n",
      "Epoch 274/500 - train_loss: 0.00546, val_loss: 0.00540\n",
      "Epoch 275/500 - train_loss: 0.00543, val_loss: 0.00537\n",
      "Epoch 276/500 - train_loss: 0.00541, val_loss: 0.00534\n",
      "Epoch 277/500 - train_loss: 0.00538, val_loss: 0.00531\n",
      "Epoch 278/500 - train_loss: 0.00536, val_loss: 0.00529\n",
      "Epoch 279/500 - train_loss: 0.00534, val_loss: 0.00526\n",
      "Epoch 280/500 - train_loss: 0.00531, val_loss: 0.00523\n",
      "Epoch 281/500 - train_loss: 0.00529, val_loss: 0.00520\n",
      "Epoch 282/500 - train_loss: 0.00527, val_loss: 0.00517\n",
      "Epoch 283/500 - train_loss: 0.00525, val_loss: 0.00515\n",
      "Epoch 284/500 - train_loss: 0.00522, val_loss: 0.00512\n",
      "Epoch 285/500 - train_loss: 0.00520, val_loss: 0.00509\n",
      "Epoch 286/500 - train_loss: 0.00518, val_loss: 0.00507\n",
      "Epoch 287/500 - train_loss: 0.00516, val_loss: 0.00504\n",
      "Epoch 288/500 - train_loss: 0.00514, val_loss: 0.00501\n",
      "Epoch 289/500 - train_loss: 0.00512, val_loss: 0.00499\n",
      "Epoch 290/500 - train_loss: 0.00509, val_loss: 0.00496\n",
      "Epoch 291/500 - train_loss: 0.00507, val_loss: 0.00494\n",
      "Epoch 292/500 - train_loss: 0.00505, val_loss: 0.00491\n",
      "Epoch 293/500 - train_loss: 0.00503, val_loss: 0.00489\n",
      "Epoch 294/500 - train_loss: 0.00501, val_loss: 0.00486\n",
      "Epoch 295/500 - train_loss: 0.00499, val_loss: 0.00484\n",
      "Epoch 296/500 - train_loss: 0.00497, val_loss: 0.00481\n",
      "Epoch 297/500 - train_loss: 0.00495, val_loss: 0.00479\n",
      "Epoch 298/500 - train_loss: 0.00493, val_loss: 0.00477\n",
      "Epoch 299/500 - train_loss: 0.00492, val_loss: 0.00474\n",
      "Epoch 300/500 - train_loss: 0.00490, val_loss: 0.00472\n",
      "Epoch 301/500 - train_loss: 0.00488, val_loss: 0.00470\n",
      "Epoch 302/500 - train_loss: 0.00486, val_loss: 0.00467\n",
      "Epoch 303/500 - train_loss: 0.00484, val_loss: 0.00465\n",
      "Epoch 304/500 - train_loss: 0.00482, val_loss: 0.00463\n",
      "Epoch 305/500 - train_loss: 0.00480, val_loss: 0.00461\n",
      "Epoch 306/500 - train_loss: 0.00479, val_loss: 0.00458\n",
      "Epoch 307/500 - train_loss: 0.00477, val_loss: 0.00456\n",
      "Epoch 308/500 - train_loss: 0.00475, val_loss: 0.00454\n",
      "Epoch 309/500 - train_loss: 0.00473, val_loss: 0.00452\n",
      "Epoch 310/500 - train_loss: 0.00472, val_loss: 0.00450\n",
      "Epoch 311/500 - train_loss: 0.00470, val_loss: 0.00448\n",
      "Epoch 312/500 - train_loss: 0.00468, val_loss: 0.00446\n",
      "Epoch 313/500 - train_loss: 0.00466, val_loss: 0.00444\n",
      "Epoch 314/500 - train_loss: 0.00465, val_loss: 0.00442\n",
      "Epoch 315/500 - train_loss: 0.00463, val_loss: 0.00440\n",
      "Epoch 316/500 - train_loss: 0.00461, val_loss: 0.00438\n",
      "Epoch 317/500 - train_loss: 0.00460, val_loss: 0.00436\n",
      "Epoch 318/500 - train_loss: 0.00458, val_loss: 0.00434\n",
      "Epoch 319/500 - train_loss: 0.00457, val_loss: 0.00432\n",
      "Epoch 320/500 - train_loss: 0.00455, val_loss: 0.00430\n",
      "Epoch 321/500 - train_loss: 0.00453, val_loss: 0.00428\n",
      "Epoch 322/500 - train_loss: 0.00452, val_loss: 0.00426\n",
      "Epoch 323/500 - train_loss: 0.00450, val_loss: 0.00424\n",
      "Epoch 324/500 - train_loss: 0.00449, val_loss: 0.00422\n",
      "Epoch 325/500 - train_loss: 0.00447, val_loss: 0.00420\n",
      "Epoch 326/500 - train_loss: 0.00446, val_loss: 0.00418\n",
      "Epoch 327/500 - train_loss: 0.00444, val_loss: 0.00417\n",
      "Epoch 328/500 - train_loss: 0.00443, val_loss: 0.00415\n",
      "Epoch 329/500 - train_loss: 0.00441, val_loss: 0.00413\n",
      "Epoch 330/500 - train_loss: 0.00440, val_loss: 0.00411\n",
      "Epoch 331/500 - train_loss: 0.00438, val_loss: 0.00410\n",
      "Epoch 332/500 - train_loss: 0.00437, val_loss: 0.00408\n",
      "Epoch 333/500 - train_loss: 0.00436, val_loss: 0.00406\n",
      "Epoch 334/500 - train_loss: 0.00434, val_loss: 0.00404\n",
      "Epoch 335/500 - train_loss: 0.00433, val_loss: 0.00403\n",
      "Epoch 336/500 - train_loss: 0.00431, val_loss: 0.00401\n",
      "Epoch 337/500 - train_loss: 0.00430, val_loss: 0.00399\n",
      "Epoch 338/500 - train_loss: 0.00429, val_loss: 0.00398\n",
      "Epoch 339/500 - train_loss: 0.00427, val_loss: 0.00396\n",
      "Epoch 340/500 - train_loss: 0.00426, val_loss: 0.00394\n",
      "Epoch 341/500 - train_loss: 0.00425, val_loss: 0.00393\n",
      "Epoch 342/500 - train_loss: 0.00423, val_loss: 0.00391\n",
      "Epoch 343/500 - train_loss: 0.00422, val_loss: 0.00390\n",
      "Epoch 344/500 - train_loss: 0.00421, val_loss: 0.00388\n",
      "Epoch 345/500 - train_loss: 0.00419, val_loss: 0.00387\n",
      "Epoch 346/500 - train_loss: 0.00418, val_loss: 0.00385\n",
      "Epoch 347/500 - train_loss: 0.00417, val_loss: 0.00384\n",
      "Epoch 348/500 - train_loss: 0.00416, val_loss: 0.00382\n",
      "Epoch 349/500 - train_loss: 0.00414, val_loss: 0.00381\n",
      "Epoch 350/500 - train_loss: 0.00413, val_loss: 0.00379\n",
      "Epoch 351/500 - train_loss: 0.00412, val_loss: 0.00378\n",
      "Epoch 352/500 - train_loss: 0.00411, val_loss: 0.00376\n",
      "Epoch 353/500 - train_loss: 0.00410, val_loss: 0.00375\n",
      "Epoch 354/500 - train_loss: 0.00408, val_loss: 0.00373\n",
      "Epoch 355/500 - train_loss: 0.00407, val_loss: 0.00372\n",
      "Epoch 356/500 - train_loss: 0.00406, val_loss: 0.00370\n",
      "Epoch 357/500 - train_loss: 0.00405, val_loss: 0.00369\n",
      "Epoch 358/500 - train_loss: 0.00404, val_loss: 0.00368\n",
      "Epoch 359/500 - train_loss: 0.00403, val_loss: 0.00366\n",
      "Epoch 360/500 - train_loss: 0.00401, val_loss: 0.00365\n",
      "Epoch 361/500 - train_loss: 0.00400, val_loss: 0.00364\n",
      "Epoch 362/500 - train_loss: 0.00399, val_loss: 0.00362\n",
      "Epoch 363/500 - train_loss: 0.00398, val_loss: 0.00361\n",
      "Epoch 364/500 - train_loss: 0.00397, val_loss: 0.00360\n",
      "Epoch 365/500 - train_loss: 0.00396, val_loss: 0.00358\n",
      "Epoch 366/500 - train_loss: 0.00395, val_loss: 0.00357\n",
      "Epoch 367/500 - train_loss: 0.00394, val_loss: 0.00356\n",
      "Epoch 368/500 - train_loss: 0.00393, val_loss: 0.00354\n",
      "Epoch 369/500 - train_loss: 0.00392, val_loss: 0.00353\n",
      "Epoch 370/500 - train_loss: 0.00391, val_loss: 0.00352\n",
      "Epoch 371/500 - train_loss: 0.00390, val_loss: 0.00351\n",
      "Epoch 372/500 - train_loss: 0.00389, val_loss: 0.00349\n",
      "Epoch 373/500 - train_loss: 0.00388, val_loss: 0.00348\n",
      "Epoch 374/500 - train_loss: 0.00386, val_loss: 0.00347\n",
      "Epoch 375/500 - train_loss: 0.00385, val_loss: 0.00346\n",
      "Epoch 376/500 - train_loss: 0.00384, val_loss: 0.00345\n",
      "Epoch 377/500 - train_loss: 0.00383, val_loss: 0.00343\n",
      "Epoch 378/500 - train_loss: 0.00383, val_loss: 0.00342\n",
      "Epoch 379/500 - train_loss: 0.00382, val_loss: 0.00341\n",
      "Epoch 380/500 - train_loss: 0.00381, val_loss: 0.00340\n",
      "Epoch 381/500 - train_loss: 0.00380, val_loss: 0.00339\n",
      "Epoch 382/500 - train_loss: 0.00379, val_loss: 0.00338\n",
      "Epoch 383/500 - train_loss: 0.00378, val_loss: 0.00336\n",
      "Epoch 384/500 - train_loss: 0.00377, val_loss: 0.00335\n",
      "Epoch 385/500 - train_loss: 0.00376, val_loss: 0.00334\n",
      "Epoch 386/500 - train_loss: 0.00375, val_loss: 0.00333\n",
      "Epoch 387/500 - train_loss: 0.00374, val_loss: 0.00332\n",
      "Epoch 388/500 - train_loss: 0.00373, val_loss: 0.00331\n",
      "Epoch 389/500 - train_loss: 0.00372, val_loss: 0.00330\n",
      "Epoch 390/500 - train_loss: 0.00371, val_loss: 0.00329\n",
      "Epoch 391/500 - train_loss: 0.00370, val_loss: 0.00328\n",
      "Epoch 392/500 - train_loss: 0.00369, val_loss: 0.00327\n",
      "Epoch 393/500 - train_loss: 0.00369, val_loss: 0.00326\n",
      "Epoch 394/500 - train_loss: 0.00368, val_loss: 0.00324\n",
      "Epoch 395/500 - train_loss: 0.00367, val_loss: 0.00323\n",
      "Epoch 396/500 - train_loss: 0.00366, val_loss: 0.00322\n",
      "Epoch 397/500 - train_loss: 0.00365, val_loss: 0.00321\n",
      "Epoch 398/500 - train_loss: 0.00364, val_loss: 0.00320\n",
      "Epoch 399/500 - train_loss: 0.00363, val_loss: 0.00319\n",
      "Epoch 400/500 - train_loss: 0.00363, val_loss: 0.00318\n",
      "Epoch 401/500 - train_loss: 0.00362, val_loss: 0.00317\n",
      "Epoch 402/500 - train_loss: 0.00361, val_loss: 0.00316\n",
      "Epoch 403/500 - train_loss: 0.00360, val_loss: 0.00315\n",
      "Epoch 404/500 - train_loss: 0.00359, val_loss: 0.00315\n",
      "Epoch 405/500 - train_loss: 0.00359, val_loss: 0.00314\n",
      "Epoch 406/500 - train_loss: 0.00358, val_loss: 0.00313\n",
      "Epoch 407/500 - train_loss: 0.00357, val_loss: 0.00312\n",
      "Epoch 408/500 - train_loss: 0.00356, val_loss: 0.00311\n",
      "Epoch 409/500 - train_loss: 0.00355, val_loss: 0.00310\n",
      "Epoch 410/500 - train_loss: 0.00355, val_loss: 0.00309\n",
      "Epoch 411/500 - train_loss: 0.00354, val_loss: 0.00308\n",
      "Epoch 412/500 - train_loss: 0.00353, val_loss: 0.00307\n",
      "Epoch 413/500 - train_loss: 0.00352, val_loss: 0.00306\n",
      "Epoch 414/500 - train_loss: 0.00351, val_loss: 0.00305\n",
      "Epoch 415/500 - train_loss: 0.00351, val_loss: 0.00304\n",
      "Epoch 416/500 - train_loss: 0.00350, val_loss: 0.00304\n",
      "Epoch 417/500 - train_loss: 0.00349, val_loss: 0.00303\n",
      "Epoch 418/500 - train_loss: 0.00349, val_loss: 0.00302\n",
      "Epoch 419/500 - train_loss: 0.00348, val_loss: 0.00301\n",
      "Epoch 420/500 - train_loss: 0.00347, val_loss: 0.00300\n",
      "Epoch 421/500 - train_loss: 0.00346, val_loss: 0.00299\n",
      "Epoch 422/500 - train_loss: 0.00346, val_loss: 0.00298\n",
      "Epoch 423/500 - train_loss: 0.00345, val_loss: 0.00298\n",
      "Epoch 424/500 - train_loss: 0.00344, val_loss: 0.00297\n",
      "Epoch 425/500 - train_loss: 0.00343, val_loss: 0.00296\n",
      "Epoch 426/500 - train_loss: 0.00343, val_loss: 0.00295\n",
      "Epoch 427/500 - train_loss: 0.00342, val_loss: 0.00294\n",
      "Epoch 428/500 - train_loss: 0.00341, val_loss: 0.00293\n",
      "Epoch 429/500 - train_loss: 0.00341, val_loss: 0.00293\n",
      "Epoch 430/500 - train_loss: 0.00340, val_loss: 0.00292\n",
      "Epoch 431/500 - train_loss: 0.00339, val_loss: 0.00291\n",
      "Epoch 432/500 - train_loss: 0.00339, val_loss: 0.00290\n",
      "Epoch 433/500 - train_loss: 0.00338, val_loss: 0.00289\n",
      "Epoch 434/500 - train_loss: 0.00337, val_loss: 0.00289\n",
      "Epoch 435/500 - train_loss: 0.00337, val_loss: 0.00288\n",
      "Epoch 436/500 - train_loss: 0.00336, val_loss: 0.00287\n",
      "Epoch 437/500 - train_loss: 0.00335, val_loss: 0.00286\n",
      "Epoch 438/500 - train_loss: 0.00335, val_loss: 0.00286\n",
      "Epoch 439/500 - train_loss: 0.00334, val_loss: 0.00285\n",
      "Epoch 440/500 - train_loss: 0.00333, val_loss: 0.00284\n",
      "Epoch 441/500 - train_loss: 0.00333, val_loss: 0.00283\n",
      "Epoch 442/500 - train_loss: 0.00332, val_loss: 0.00283\n",
      "Epoch 443/500 - train_loss: 0.00332, val_loss: 0.00282\n",
      "Epoch 444/500 - train_loss: 0.00331, val_loss: 0.00281\n",
      "Epoch 445/500 - train_loss: 0.00330, val_loss: 0.00280\n",
      "Epoch 446/500 - train_loss: 0.00330, val_loss: 0.00280\n",
      "Epoch 447/500 - train_loss: 0.00329, val_loss: 0.00279\n",
      "Epoch 448/500 - train_loss: 0.00328, val_loss: 0.00278\n",
      "Epoch 449/500 - train_loss: 0.00328, val_loss: 0.00278\n",
      "Epoch 450/500 - train_loss: 0.00327, val_loss: 0.00277\n",
      "Epoch 451/500 - train_loss: 0.00327, val_loss: 0.00276\n",
      "Epoch 452/500 - train_loss: 0.00326, val_loss: 0.00276\n",
      "Epoch 453/500 - train_loss: 0.00325, val_loss: 0.00275\n",
      "Epoch 454/500 - train_loss: 0.00325, val_loss: 0.00274\n",
      "Epoch 455/500 - train_loss: 0.00324, val_loss: 0.00274\n",
      "Epoch 456/500 - train_loss: 0.00324, val_loss: 0.00273\n",
      "Epoch 457/500 - train_loss: 0.00323, val_loss: 0.00272\n",
      "Epoch 458/500 - train_loss: 0.00323, val_loss: 0.00272\n",
      "Epoch 459/500 - train_loss: 0.00322, val_loss: 0.00271\n",
      "Epoch 460/500 - train_loss: 0.00321, val_loss: 0.00270\n",
      "Epoch 461/500 - train_loss: 0.00321, val_loss: 0.00270\n",
      "Epoch 462/500 - train_loss: 0.00320, val_loss: 0.00269\n",
      "Epoch 463/500 - train_loss: 0.00320, val_loss: 0.00268\n",
      "Epoch 464/500 - train_loss: 0.00319, val_loss: 0.00268\n",
      "Epoch 465/500 - train_loss: 0.00319, val_loss: 0.00267\n",
      "Epoch 466/500 - train_loss: 0.00318, val_loss: 0.00266\n",
      "Epoch 467/500 - train_loss: 0.00318, val_loss: 0.00266\n",
      "Epoch 468/500 - train_loss: 0.00317, val_loss: 0.00265\n",
      "Epoch 469/500 - train_loss: 0.00317, val_loss: 0.00265\n",
      "Epoch 470/500 - train_loss: 0.00316, val_loss: 0.00264\n",
      "Epoch 471/500 - train_loss: 0.00315, val_loss: 0.00263\n",
      "Epoch 472/500 - train_loss: 0.00315, val_loss: 0.00263\n",
      "Epoch 473/500 - train_loss: 0.00314, val_loss: 0.00262\n",
      "Epoch 474/500 - train_loss: 0.00314, val_loss: 0.00262\n",
      "Epoch 475/500 - train_loss: 0.00313, val_loss: 0.00261\n",
      "Epoch 476/500 - train_loss: 0.00313, val_loss: 0.00260\n",
      "Epoch 477/500 - train_loss: 0.00312, val_loss: 0.00260\n",
      "Epoch 478/500 - train_loss: 0.00312, val_loss: 0.00259\n",
      "Epoch 479/500 - train_loss: 0.00311, val_loss: 0.00259\n",
      "Epoch 480/500 - train_loss: 0.00311, val_loss: 0.00258\n",
      "Epoch 481/500 - train_loss: 0.00310, val_loss: 0.00258\n",
      "Epoch 482/500 - train_loss: 0.00310, val_loss: 0.00257\n",
      "Epoch 483/500 - train_loss: 0.00309, val_loss: 0.00256\n",
      "Epoch 484/500 - train_loss: 0.00309, val_loss: 0.00256\n",
      "Epoch 485/500 - train_loss: 0.00308, val_loss: 0.00255\n",
      "Epoch 486/500 - train_loss: 0.00308, val_loss: 0.00255\n",
      "Epoch 487/500 - train_loss: 0.00307, val_loss: 0.00254\n",
      "Epoch 488/500 - train_loss: 0.00307, val_loss: 0.00254\n",
      "Epoch 489/500 - train_loss: 0.00306, val_loss: 0.00253\n",
      "Epoch 490/500 - train_loss: 0.00306, val_loss: 0.00253\n",
      "Epoch 491/500 - train_loss: 0.00305, val_loss: 0.00252\n",
      "Epoch 492/500 - train_loss: 0.00305, val_loss: 0.00252\n",
      "Epoch 493/500 - train_loss: 0.00305, val_loss: 0.00251\n",
      "Epoch 494/500 - train_loss: 0.00304, val_loss: 0.00250\n",
      "Epoch 495/500 - train_loss: 0.00304, val_loss: 0.00250\n",
      "Epoch 496/500 - train_loss: 0.00303, val_loss: 0.00249\n",
      "Epoch 497/500 - train_loss: 0.00303, val_loss: 0.00249\n",
      "Epoch 498/500 - train_loss: 0.00302, val_loss: 0.00248\n",
      "Epoch 499/500 - train_loss: 0.00302, val_loss: 0.00248\n",
      "Epoch 500/500 - train_loss: 0.00301, val_loss: 0.00247\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    x_val=X_val,\n",
    "    y_val=y_val,\n",
    "    learning_rate=0.01,\n",
    "    num_epochs=500,\n",
    "    early_stopping=EarlyStopping(patience=35)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:36.447575800Z",
     "start_time": "2024-02-01T12:15:34.023691900Z"
    }
   },
   "id": "bdd159b6bb2e681a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.88      0.93         8\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.95      0.96      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['setosa', 'versicolor', 'virginica'])\n",
    "disp.plot(cmap='Greens')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T12:15:37.671392Z",
     "start_time": "2024-02-01T12:15:36.448575800Z"
    }
   },
   "id": "58e44998a2dcef7c",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
